{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redes neuronales convolucionales con TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Esta notebook fue creada originalmente como un blog post por [Raúl E. López Briega](https://relopezbriega.com.ar/) en [Matemáticas, Analisis de datos y Python](https://relopezbriega.github.io). El contenido esta bajo la licencia BSD.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img title=\"Redes neuronales convolucionales con TensorFlow\" alt=\"Redes neuronales convolucionales con TensorFlow\" src=\"https://relopezbriega.github.io/images/convNetTensorFlow.jpg\" high=\"400px\" width=\"600px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducción\n",
    "\n",
    "De más esta decir que el sentido de la [visión](https://es.wikipedia.org/wiki/Visi%C3%B3n) es uno de los grandes prodigios de la Naturaleza. En fracciones de segundos, podemos identificar objetos dentro de nuestro campo de visión, sin siquiera detenernos a pensar en ello. Pero no sólo podemos nombrar estos objetos que observamos, sino que también podemos percibir su profundidad, distinguir perfectamente sus contornos, y separarlos de sus fondos.\n",
    "De alguna manera los ojos captan datos de [píxeles](https://es.wikipedia.org/wiki/P%C3%ADxel), pero el cerebro transforma esa información en características más significativas - *líneas, curvas y formas* - que podrían indicar, por ejemplo, que estamos mirando a una persona.\n",
    "\n",
    "Gracias a que el área del cerebro responsable de la [visión](https://es.wikipedia.org/wiki/Visi%C3%B3n) es una de las zonas más estudiadas y que más conocemos; sabemos que la [corteza visual](https://es.wikipedia.org/wiki/Corteza_visual) contiene una disposición jerárquica compleja de [neuronas](https://es.wikipedia.org/wiki/Neurona).  Por ejemplo, la información visual es introducida en la corteza a través del área visual primaria, llamada V1. Las [neuronas](https://es.wikipedia.org/wiki/Neurona) de V1 se ocupan de características visuales de bajo nivel, tales como pequeños segmentos de contorno, componentes de pequeña escala del movimiento, [disparidad binocular](https://es.wikipedia.org/wiki/Disparidad_binocular), e información básica de contraste y color. V1 luego alimenta de información a otras áreas, como V2, V4 y V5. Cada una de estas áreas se ocupa de los aspectos más específicos o abstractas de la información. Por ejemplo, las [neuronas](https://es.wikipedia.org/wiki/Neurona) en V4 se ocupan de objetos de mediana complejidad, tales como formas de estrellas en diferentes colores. La [corteza visual](https://es.wikipedia.org/wiki/Corteza_visual) de los animales es el más potente sistema de procesamiento visual que conocemos, por lo que suena lógico inspirarse en ella para crear una variante de [redes neuronales artificiales](https://es.wikipedia.org/wiki/Red_neuronal_artificial) que ayude a identificar imágenes; es así como surgen las [redes neuronales convolucionales](https://es.wikipedia.org/wiki/Redes_neuronales_convolucionales).\n",
    "\n",
    "## ¿Qué son las Redes Neuronales Convolucionales?\n",
    "\n",
    "Las [redes neuronales convolucionales](https://es.wikipedia.org/wiki/Redes_neuronales_convolucionales) son muy similares a las [redes neuronales](https://es.wikipedia.org/wiki/Red_neuronal_artificial) ordinarias como el [perceptron multicapa](https://es.wikipedia.org/wiki/Perceptr%C3%B3n_multicapa) que vimos en el [artículo anterior](https://relopezbriega.github.io/blog/2016/06/05/tensorflow-y-redes-neuronales/); se componen de [neuronas](https://es.wikipedia.org/wiki/Neurona) que tienen *pesos* y *sesgos* que pueden aprender. Cada [neurona](https://es.wikipedia.org/wiki/Neurona) recibe algunas entradas, realiza un [producto escalar](https://es.wikipedia.org/wiki/Producto_escalar) y luego aplica una función de activación. Al igual que en el [perceptron multicapa](https://es.wikipedia.org/wiki/Perceptr%C3%B3n_multicapa) también vamos a tener una *función de pérdida o costo* (por ejemplo SVM / Softmax) sobre la última capa, la cual estará totalmente conectada. Lo que diferencia a las [redes neuronales convolucionales](https://es.wikipedia.org/wiki/Redes_neuronales_convolucionales) es que suponen explícitamente que las entradas son imágenes, lo que nos permite codificar ciertas propiedades en la arquitectura; permitiendo ganar en eficiencia y reducir la cantidad de parámetros en la red. Las [redes neuronales convolucionales](https://es.wikipedia.org/wiki/Redes_neuronales_convolucionales) vienen a solucionar el problema de que las [redes neuronales](https://es.wikipedia.org/wiki/Red_neuronal_artificial) ordinarias no escalan bien para imágenes de mucha definición; por ejemplo en el problema de [MNIST](https://relopezbriega.github.io/blog/2016/06/05/tensorflow-y-redes-neuronales/), las imágenes son de 28x28; por lo que una sola [neurona](https://es.wikipedia.org/wiki/Neurona) plenamente conectado en una primera capa oculta de una [red neuronal](https://es.wikipedia.org/wiki/Red_neuronal_artificial) ordinaria tendría 28 x 28  = 784 pesos. Esta cantidad todavía parece manejable, pero es evidente que esta estructura totalmente conectado no funciona bien con imágenes más grandes. Si tomamos el caso de una imagen de mayor tamaño, por ejemplo de 200x200 con colores RGB, daría lugar a [neuronas](https://es.wikipedia.org/wiki/Neurona) que tienen 200 x 200 x 3  = 120.000 pesos. Por otra parte, el contar con tantos parámetros, también sería un desperdicio de recursos y conduciría rápidamente a [sobreajuste](https://relopezbriega.github.io/blog/2016/05/29/machine-learning-con-python-sobreajuste/).\n",
    "\n",
    "Las [redes neuronales convolucionales](https://es.wikipedia.org/wiki/Redes_neuronales_convolucionales) trabajan modelando de forma consecutiva pequeñas piezas de información, y luego combinando esta información en las capas más profundas de la red. Una manera de entenderlas es que la primera capa intentará detectar los bordes y establecer patrones de detección de bordes. Luego, las capas posteriores trataran de combinarlos en formas más simples y, finalmente, en patrones de las diferentes posiciones de los objetos, iluminación, escalas, etc. Las capas finales intentarán hacer coincidir una imagen de entrada con todas los patrones y arribar a una predicción final como una suma ponderada de todos ellos. De esta forma las [redes neuronales convolucionales](https://es.wikipedia.org/wiki/Redes_neuronales_convolucionales) son capaces de modelar complejas variaciones y comportamientos dando predicciones bastantes precisas.\n",
    "\n",
    "## Estructura de las Redes Neuronales Convolucionales\n",
    "\n",
    "En general, las [redes neuronales convolucionales](https://es.wikipedia.org/wiki/Redes_neuronales_convolucionales) van a estar construidas con una estructura que contendrá 3 tipos distintos de capas:\n",
    "\n",
    "1. Una capa convolucional, que es la que le da le nombre a la red.\n",
    "2. Una capa de reducción o de *pooling*, la cual va a reducir la cantidad de parámetros al quedarse con las características más comunes.\n",
    "3. Una capa clasificadora totalmente conectada, la cual nos va dar el resultado final de la red.\n",
    "\n",
    "Profundicemos un poco en cada una de ellas.\n",
    "\n",
    "### Capa convolucional\n",
    "\n",
    "Como dijimos anteriormente, lo que distingue a las [redes neuronales convolucionales](https://es.wikipedia.org/wiki/Redes_neuronales_convolucionales) de cualquier otra [red neuronal](https://es.wikipedia.org/wiki/Red_neuronal_artificial) es utilizan un operación llamada [convolución](https://es.wikipedia.org/wiki/Convoluci%C3%B3n) en alguna de sus capas; en lugar de utilizar la multiplicación de matrices que se aplica generalmente.\n",
    "La operación de [convolución](https://es.wikipedia.org/wiki/Convoluci%C3%B3n) recibe como *entrada o input* la imagen y luego aplica sobre ella un *filtro o kernel* que nos devuelve un *mapa de las características* de la imagen original, de esta forma logramos reducir el tamaño de los parámetros.\n",
    "La [convolución](https://es.wikipedia.org/wiki/Convoluci%C3%B3n) aprovecha tres ideas importantes que pueden ayudar a mejorar cualquier sistema de [machine learning](https://es.wikipedia.org/wiki/Aprendizaje_autom%C3%A1tico), ellas son: \n",
    "* **interacciones dispersas**, ya que al aplicar un filtro de menor tamaño sobre la entrada original podemos reducir drásticamente la cantidad de parámetros y cálculos;\n",
    "* los **parámetros compartidos**, que hace referencia a compartir los parámetros entre los distintos tipos de filtros, ayudando también a mejorar la eficiencia del sistema; y\n",
    "* las **representaciones equivariante**, que indican que si las entradas cambian, las salidas van a cambiar también en forma similar. \n",
    "\n",
    "Por otra parte, la [convolución](https://es.wikipedia.org/wiki/Convoluci%C3%B3n) proporciona un medio para trabajar con entradas de tamaño variable, lo que puede ser también muy conveniente.\n",
    "\n",
    "<img alt=\"Convolución\" title=\"Convolución\" src=\"https://relopezbriega.github.io/images/conv_layer.png\">\n",
    "\n",
    "\n",
    "### Capa de reducción o pooling\n",
    "\n",
    "La capa de reducción o *pooling* se coloca generalmente después de la capa *convolucional*. Su utilidad principal radica en la reducción de las dimensiones espaciales (ancho x alto) del volumen de entrada para la siguiente capa *convolucional*. No afecta a la dimensión de profundidad del volumen.\n",
    "La operación realizada por esta capa también se llama *reducción de muestreo*, ya que la reducción de tamaño conduce también a la pérdida de información. Sin embargo, una pérdida de este tipo puede ser beneficioso para la red por dos razones:\n",
    "\n",
    "* la disminución en el tamaño conduce a una menor sobrecarga de cálculo para las próximas capas de la red;\n",
    "* también trabaja para reducir el [sobreajuste](https://relopezbriega.github.io/blog/2016/05/29/machine-learning-con-python-sobreajuste/).\n",
    "\n",
    "La operación que se suele utilizar en esta capa es *max-pooling*, que divide a la imagen de entrada en un conjunto de rectángulos y, respecto de cada subregión, se va quedando con el máximo valor.\n",
    "\n",
    "<img alt=\"max pooling\" title=\"max pooling\" src=\"https://relopezbriega.github.io/images/Max_pooling.png\">\n",
    "\n",
    "\n",
    "### Capa clasificadora totalmente conectada\n",
    "\n",
    "Al final de las capas *convolucional* y de *pooling*, las redes utilizan generalmente capas completamente conectados en la que cada pixel se considera como una [neurona](https://es.wikipedia.org/wiki/Neurona) separada al igual que en una [red neuronal](https://es.wikipedia.org/wiki/Red_neuronal_artificial) regular. Esta última capa clasificadora tendrá tantas [neuronas](https://es.wikipedia.org/wiki/Neurona) como el número de clases que se debe predecir.\n",
    "\n",
    "## Ejemplo en TensorFlow\n",
    "\n",
    "Luego de toda esta introducción teórica es tiempo de pasar a la acción y ver como podemos aplicar todo lo que hemos aprendimos para crear una [red neuronal convolucional](https://es.wikipedia.org/wiki/Redes_neuronales_convolucionales) con la ayuda de [TensorFlow](https://www.tensorflow.org/). Para esto vamos volver a utilizar el [conjunto de datos](https://es.wikipedia.org/wiki/Conjunto_de_datos) [MNIST](https://colah.github.io/posts/2014-10-Visualizing-MNIST/), pero esta vez vamos a clasificar los digitos utilizando una [red neuronal convolucional](https://es.wikipedia.org/wiki/Redes_neuronales_convolucionales).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# importamos la libreria\n",
    "import tensorflow as tf\n",
    "\n",
    "# importando el dataset\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Parametros\n",
    "tasa_aprendizaje = 0.001\n",
    "epocas = 200000\n",
    "lote = 128\n",
    "mostrar_paso = 100\n",
    "\n",
    "# Parametros de la red\n",
    "n_entradas = 784 # datos de MNIST(forma img: 28*28)\n",
    "n_clases = 10 # Total de clases a clasificar (0-9 digitos)\n",
    "dropout = 0.75 # Dropout, probabilidad para quedarse con unidades\n",
    "\n",
    "# input para los grafos\n",
    "x = tf.placeholder(tf.float32, [None, n_entradas])\n",
    "y = tf.placeholder(tf.float32, [None, n_clases])\n",
    "keep_prob = tf.placeholder(tf.float32) #dropout "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Creación del modelo\n",
    "def conv2d(x, W, b, strides=1):\n",
    "    # capa convolucional con activacion relu\n",
    "    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "\n",
    "def maxpool2d(x, k=2):\n",
    "    # capa de pooling con max pooling\n",
    "    return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1],\n",
    "                          padding='SAME')\n",
    "\n",
    "# armado de la red\n",
    "def conv_net(x, weights, biases, dropout):\n",
    "    # cambiar la forma de la imagen\n",
    "    x = tf.reshape(x, shape=[-1, 28, 28, 1])\n",
    "\n",
    "    # capa convolucional\n",
    "    conv1 = conv2d(x, pesos['pc1'], sesgo['sc1'])\n",
    "    # Max Pooling (reducción de muestreo)\n",
    "    conv1 = maxpool2d(conv1, k=2)\n",
    "\n",
    "    # capa convolucional\n",
    "    conv2 = conv2d(conv1, pesos['pc2'], sesgo['sc2'])\n",
    "    # Max Pooling (reducción de muestreo)\n",
    "    conv2 = maxpool2d(conv2, k=2)\n",
    "\n",
    "    # capa clasificadora totalmente conectada\n",
    "    fc1 = tf.reshape(conv2, [-1, pesos['pd1'].get_shape().as_list()[0]])\n",
    "    fc1 = tf.add(tf.matmul(fc1, pesos['pd1']), sesgo['sd1'])\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "    # aplicar descarte\n",
    "    fc1 = tf.nn.dropout(fc1, dropout)\n",
    "\n",
    "    # Output, prediccion de la clase\n",
    "    out = tf.add(tf.matmul(fc1, pesos['out']), sesgo['out'])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Definimos los pesos y sesgo de cada capa\n",
    "pesos = {\n",
    "    # 5x5 conv, 1 input, 32 outputs\n",
    "    'pc1': tf.Variable(tf.random_normal([5, 5, 1, 32])),\n",
    "    # 5x5 conv, 32 inputs, 64 outputs\n",
    "    'pc2': tf.Variable(tf.random_normal([5, 5, 32, 64])),\n",
    "    # totalmente conectada, 7*7*64 inputs, 1024 outputs\n",
    "    'pd1': tf.Variable(tf.random_normal([7*7*64, 1024])),\n",
    "    # 1024 inputs, 10 outputs (prediccion de clase)\n",
    "    'out': tf.Variable(tf.random_normal([1024, n_clases]))\n",
    "}\n",
    "\n",
    "sesgo = {\n",
    "    'sc1': tf.Variable(tf.random_normal([32])),\n",
    "    'sc2': tf.Variable(tf.random_normal([64])),\n",
    "    'sd1': tf.Variable(tf.random_normal([1024])),\n",
    "    'out': tf.Variable(tf.random_normal([n_clases]))\n",
    "}\n",
    "\n",
    "# Construct model\n",
    "pred = conv_net(x, pesos, sesgo, keep_prob)\n",
    "\n",
    "# Define loss and optimizer\n",
    "costo = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(pred, y))\n",
    "optimizador = tf.train.AdamOptimizer(learning_rate=tasa_aprendizaje\n",
    "                                    ).minimize(costo)\n",
    "\n",
    "# Evaluate model\n",
    "pred_correcta = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "precision = tf.reduce_mean(tf.cast(pred_correcta, tf.float32))\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteración:  12800 costo = 4224.402344 precision = 0.78906\n",
      "Iteración:  25600 costo = 1844.304932 precision = 0.89844\n",
      "Iteración:  38400 costo = 289.222961 precision = 0.95312\n",
      "Iteración:  51200 costo = 442.070557 precision = 0.95312\n",
      "Iteración:  64000 costo = 275.925751 precision = 0.96094\n",
      "Iteración:  76800 costo = 124.911362 precision = 0.96875\n",
      "Iteración:  89600 costo = 302.610291 precision = 0.96875\n",
      "Iteración:  102400 costo = 377.000092 precision = 0.95312\n",
      "Iteración:  115200 costo = 348.436188 precision = 0.99219\n",
      "Iteración:  128000 costo = 131.974304 precision = 0.99219\n",
      "Iteración:  140800 costo = 442.505676 precision = 0.96875\n",
      "Iteración:  153600 costo = 10.694885 precision = 0.98438\n",
      "Iteración:  166400 costo = 39.013718 precision = 0.98438\n",
      "Iteración:  179200 costo = 278.081543 precision = 0.96094\n",
      "Iteración:  192000 costo = 91.298866 precision = 0.97656\n",
      "Optimización terminada!\n",
      "Precisión evalución: 0.98\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    paso = 1\n",
    "    # Keep training until reach max iterations\n",
    "    while paso * lote < epocas:\n",
    "        batch_x, batch_y = mnist.train.next_batch(lote)\n",
    "        # Run optimization op (backprop)\n",
    "        sess.run(optimizador, feed_dict={x: batch_x, y: batch_y,\n",
    "                                       keep_prob: dropout})\n",
    "        if paso % mostrar_paso == 0:\n",
    "            # Calculate batch loss and accuracy\n",
    "            loss, acc = sess.run([costo, precision], feed_dict={x: batch_x,\n",
    "                                                              y: batch_y,\n",
    "                                                              keep_prob: 1.})\n",
    "            print(\"Iteración: {0: 04d} costo = {1:.6f} precision = {2:.5f}\"\n",
    "                 .format(paso*lote, loss, acc))\n",
    "        paso += 1\n",
    "    print(\"Optimización terminada!\")\n",
    "\n",
    "    # Calculala precisión sobre los datos de evaluación\n",
    "    print(\"Precisión evalución: {0:.2f}\".format(\n",
    "        sess.run(precision, feed_dict={x: mnist.test.images[:256],\n",
    "                                      y: mnist.test.labels[:256],\n",
    "                                      keep_prob: 1.})))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver, utilizando [redes neuronales convolucionales](https://es.wikipedia.org/wiki/Redes_neuronales_convolucionales) en lugar de un [peceptron multicapa](https://es.wikipedia.org/wiki/Perceptr%C3%B3n_multicapa) como hicimos en el [artículo anterior](https://relopezbriega.github.io/blog/2016/06/05/tensorflow-y-redes-neuronales/); logramos una precisión de 98%, una mejora bastante significativa.\n",
    "\n",
    "Aquí termina el artículo, espero que les haya resultado interesante y los motive a explorar el fascinante mundo de las [redes neuronales](https://es.wikipedia.org/wiki/Red_neuronal_artificial).\n",
    "\n",
    "Saludos!\n",
    "\n",
    "*Este post fue escrito utilizando IPython notebook. Pueden descargar este [notebook](https://github.com/relopezbriega/relopezbriega.github.io/blob/master/downloads/ConvTensor.ipynb) o ver su version estática en [nbviewer](https://nbviewer.ipython.org/github/relopezbriega/relopezbriega.github.io/blob/master/downloads/ConvTensor.ipynb).*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
