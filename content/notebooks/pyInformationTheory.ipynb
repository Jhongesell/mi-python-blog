{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducción a la Teoría de la información "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Esta notebook fue creada originalmente como un blog post por [Raúl E. López Briega](https://relopezbriega.com.ar/) en [Matemáticas, análisis de datos y python](https://relopezbriega.github.io). El contenido esta bajo la licencia BSD.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img alt=\"NLP\" title=\"NLP\" src=\"https://relopezbriega.github.io/images/shannon.jpg\" width=\"60%\" height=\"60%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> \"La información es la resolución de la incertidumbre\" \n",
    "\n",
    "**[Claude Shannon](https://es.wikipedia.org/wiki/Claude_Elwood_Shannon)**\n",
    "\n",
    "> \"Lo que está en el corazón de cada ser vivo no es *un fuego*, ni un *aliento cálido*, ni una *chispa de vida*. Es información, palabras, instrucciones ... Si quieres entender la vida... piensa en la tecnología de la información\"\n",
    "\n",
    "**[Richard Dawkins](https://es.wikipedia.org/wiki/Richard_Dawkins)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducción\n",
    "\n",
    "Muchas veces hemos escuchado decir que vivimos en la [era de la información](https://es.wikipedia.org/wiki/Era_de_la_informaci%C3%B3n). La *información* parece estar en todo los que nos rodea. Ya sea que consideremos a las computadoras, la evolución, la física, la [inteligencia artificial](https://relopezbriega.github.io/blog/2017/06/05/introduccion-a-la-inteligencia-artificial/), o nuestro cerebro; podemos llegar a la conclusión de que su comportamiento esta principalmente determinado por la forma en que procesan la *información*. \n",
    "\n",
    "La idea de la *información* nació del antiguo arte de la codificación y decodificación de códigos. Los encargados de esconder los secretos de estado durante la segunda guerra mundial utilizaban, en esencia, métodos para ocultar *información* y transmitirla de un lugar a otro. Cuando el arte de quebrar estos códigos se combinó con la ciencia de la [Termodinámica](https://es.wikipedia.org/wiki/Termodin%C3%A1mica), la rama de la [física](https://es.wikipedia.org/wiki/F%C3%ADsica) encargada del estudio de la interacción entre el calor y otras manifestaciones de la energía; surgió lo que hoy conocemos como [Teoría de la información](https://es.wikipedia.org/wiki/Teor%C3%ADa_de_la_informaci%C3%B3n). Esta teoría fue una idea revolucionaria que inmediatamente transformó el campo de las comunicaciones y preparó el camino para la *era de las computadoras*. Pero las ideas de la [Teoría de la información](https://es.wikipedia.org/wiki/Teor%C3%ADa_de_la_informaci%C3%B3n) no solo gobiernan las comunicaciones y los *bits* y *bytes* de las computadoras modernas; sino que también describen el comportamiento del *mundo [subatómico](https://es.wikipedia.org/wiki/Part%C3%ADcula_subat%C3%B3mica)*, e incluso de toda la vida en la Tierra.     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Qué es la información?\n",
    "\n",
    "Hasta no hace no tanto tiempo atrás, nuestro conocimiento de la *información* era bastante vago y limitado. En 1948, [Claude Shannon](https://es.wikipedia.org/wiki/Claude_Elwood_Shannon) publicó un artículo titulado *[\"Una teoría matemática de la comunicación\"](https://es.wikipedia.org/wiki/Una_teor%C3%ADa_matem%C3%A1tica_de_la_comunicaci%C3%B3n)*, el cual transformó para siempre la forma en que entendemos la *información*. La [Teoría de la información](https://es.wikipedia.org/wiki/Teor%C3%ADa_de_la_informaci%C3%B3n) de [Shannon](https://es.wikipedia.org/wiki/Claude_Elwood_Shannon) proporciona una definición matemática de *información* y describe con precisión cuánta *información* se puede comunicar entre los diferentes elementos de un sistema. La teoría de [Shannon](https://es.wikipedia.org/wiki/Claude_Elwood_Shannon) respalda nuestra comprensión de cómo se relacionan las *señales y el ruido*, y por qué existen límites definidos para la velocidad a la que se puede comunicar la *información* dentro de cualquier sistema, ya sea creado por el hombre o biológico. La habilidad de separar la *señal* del *ruido*, para extraer la *información* en los datos, se ha vuelto crucial en las telecomunicaciones modernas. \n",
    "\n",
    "La [Teoría de la información](https://es.wikipedia.org/wiki/Teor%C3%ADa_de_la_informaci%C3%B3n) es tan poderosa porque la *información* es física. La *información* no es solo un concepto abstracto, y no solo son hechos o figuras, fechas o nombres. Es una propiedad concreta de la materia y la energía que es cuantificable y mensurable. Es tan real como el peso de un trozo de plomo o la energía almacenada en una ojiva atómica, y al igual que la masa y la energía, la *información* está sujeta a un conjunto de leyes físicas que dictan cómo puede comportarse, cómo la *información* puede ser manipulada, transferida, duplicada, borrada o destruida. Y todo en el universo debe obedecer las leyes de la *información*, porque todo en el universo está formado por la *información* que contiene.\n",
    "\n",
    "Según la perspectiva de la *información* de [Shannon](https://es.wikipedia.org/wiki/Claude_Elwood_Shannon), el significado no es importante, sino que lo que importa es *cuánta información es transmitida* por un mensaje. Una de las grandes intuiciones que tuvo [Shannon](https://es.wikipedia.org/wiki/Claude_Elwood_Shannon) fue darse cuenta que cualquier pregunta que tenga una respuesta finita puede ser respondida por una cadena de preguntas por sí o por no. Así es como surge el concepto de *[Bit](https://es.wikipedia.org/wiki/Bit)*.   \n",
    "\n",
    "### Bits\n",
    "\n",
    "Un *[Bit](https://es.wikipedia.org/wiki/Bit)* es la unidad fundamental en la que podemos medir la *información* y nos permite decidir entre dos alternativas igualmente probables. La palabra *[Bit](https://es.wikipedia.org/wiki/Bit)* deriva de <em><strong>bi</strong>nary digi<strong>t</strong></em>, o sea [dígito binario](https://es.wikipedia.org/wiki/Sistema_binario), los cuales son representados por 1s y 0s. Pero si bien la palabra *[Bit](https://es.wikipedia.org/wiki/Bit)* deriva de <em><strong>bi</strong>nary digi<strong>t</strong></em> no debemos confundirlos, ya que representan entidades distintas. Un *[Bit](https://es.wikipedia.org/wiki/Bit)* representa una *cantidad de información* definitiva. En cambio, un [dígito binario](https://es.wikipedia.org/wiki/Sistema_binario) es el valor de una variable [binaria](https://es.wikipedia.org/wiki/Sistema_binario), el cual como ya dijimos puede ser 0 o 1; pero un [dígito binario](https://es.wikipedia.org/wiki/Sistema_binario) no representa *información* en sí misma.\n",
    "\n",
    "Ahora bien, volviendo a las preguntas por sí o por no que mencionamos antes; responder cada una de estas preguntas requiere un *[Bit](https://es.wikipedia.org/wiki/Bit)* de *información*. Sólo necesitamos un *[Bit](https://es.wikipedia.org/wiki/Bit)* para responder una pregunta como ¿sos un hombre o una mujer?; el 0 puede significar hombre y el 1 mujer. Con simplemente transmitir ese dígito en el mensaje, estamos transmitiendo la respuesta. Pero aquí viene otra de las grandes intuiciones de [Shannon](https://es.wikipedia.org/wiki/Claude_Elwood_Shannon); tampoco importa la *forma* que tome el mensaje, puede ser una luz roja versus una luz verde; o una bandera blanca y otra roja; realmente no importa el medio que se utilice, el mensaje siempre contiene un *[Bit](https://es.wikipedia.org/wiki/Bit)* de *información*. \n",
    "\n",
    "Y ¿qué pasa con otro tipo de preguntas? preguntas como adivinar un número entero entre 1 y 1000, o como, ¿cuál es la capital de Islandia? Estas preguntas también pueden ser respondidas con una cadena de *[Bits](https://es.wikipedia.org/wiki/Bit)*. El lenguaje no es más que una cadena de símbolos y cualquier símbolo puede ser representado con una cadena de *[Bits](https://es.wikipedia.org/wiki/Bit)*. Por lo tanto, cualquier respuesta que pueda ser escrita en un lenguaje puede ser representada con una cadena de *[Bits](https://es.wikipedia.org/wiki/Bit)*, de 1s y 0s. Los *[Bits](https://es.wikipedia.org/wiki/Bit)* son el medio fundamental de la *información*.\n",
    "\n",
    "Esta realización, que cualquier información, cualquier respuesta, puede ser codificada en una cadena de *[Bits](https://es.wikipedia.org/wiki/Bit)*, nos abre la puerta para pensar que entonces debe existir una forma de medir *cuánta información* hay en un mensaje.¿Cuál es la mínima cantidad de *[Bits](https://es.wikipedia.org/wiki/Bit)* para codificar un mensaje? Por ejemplo, para responder la pregunta planteada anteriormente de adivinar un número entero entre 1 y 1000, no se necesitan más que 10 *[Bits](https://es.wikipedia.org/wiki/Bit)*!. [Shannon](https://es.wikipedia.org/wiki/Claude_Elwood_Shannon) encontró que una pregunta con $N$ posibles resultados puede ser respondida con una cadena de *[Bits](https://es.wikipedia.org/wiki/Bit)* de $log_2 N$ *[Bits](https://es.wikipedia.org/wiki/Bit)*; es decir que solo necesitamos $log_2 N$ *[Bits](https://es.wikipedia.org/wiki/Bit)* de *información* para distinguir entre $N$ posibilidades. Si no me creen, más abajo les dejo para botón para jugar a adivinar el número. (Si les consume más de 10 bits adivinar, no están utilizando la estrategia correcta!).\n",
    "\n",
    "Todo esto último relacionado a cómo medir *cuánta información* contiene un mensaje nos lleva a otro de los conceptos fundamentales de la [Teoría de la información](https://es.wikipedia.org/wiki/Teor%C3%ADa_de_la_informaci%C3%B3n), el concepto de <a href=\"https://es.wikipedia.org/wiki/Entrop%C3%ADa_(informaci%C3%B3n)\" target=\"_blank\">Entropía</a>. \n",
    "<br>\n",
    "<button onclick=\"adivinar_numero()\">Jugar a Adivinar el número!</button>\n",
    "\n",
    "<script>\n",
    "function adivinar_numero(){\n",
    "    var numero_a_adivinar = Math.floor(Math.random()*1000);\n",
    "    var bits = 1;\n",
    "    var numero_usuario = prompt(\"Adivine un número entero entre 1 y 1000\\nIngrese un número entre 1 y 1000: \");\n",
    "\n",
    "    while (numero_usuario != numero_a_adivinar) {\n",
    "        if (numero_usuario < numero_a_adivinar) {\n",
    "            numero_usuario = prompt(\"Su número es muy bajo!\\nIngrese otro número entre 1 y 1000:\");\n",
    "            bits++;\n",
    "        } else {\n",
    "            numero_usuario = prompt(\"Su número es muy alto!\\nIngrese otro número entre 1 y 1000:\");\n",
    "            bits++;\n",
    "        }\n",
    "    }\n",
    "    alert(\"Felicidades el número es \" + numero_usuario + \" y ha utilizado \" + bits + \" bits!\");\n",
    "}\n",
    "</script>\n",
    "\n",
    "\n",
    "\n",
    "## Entropía\n",
    "\n",
    "La idea central de la [Teoría de la información](https://es.wikipedia.org/wiki/Teor%C3%ADa_de_la_informaci%C3%B3n) de [Shannon](https://es.wikipedia.org/wiki/Claude_Elwood_Shannon) es la <a href=\"https://es.wikipedia.org/wiki/Entrop%C3%ADa_(informaci%C3%B3n)\" target=\"_blank\">Entropía</a>. La *información* y la <a href=\"https://es.wikipedia.org/wiki/Entrop%C3%ADa_(informaci%C3%B3n)\" target=\"_blank\">Entropía</a> están intimimamente relacionadas, ya que esta última es en sí misma una *medida de información*. Cuando [Shannon](https://es.wikipedia.org/wiki/Claude_Elwood_Shannon) comenzó a desarrollar su teoría, encontró una formula que le permitía analizar la *información* en un mensaje en términos de *[Bits](https://es.wikipedia.org/wiki/Bit)*. Esta formula que encontró mide, a grandes rasgos, cuan poco predecible es una cadena de *[Bits](https://es.wikipedia.org/wiki/Bit)*. Mientras menos predecible, existen menos probabilidades de poder generar el mensaje completo desde una cadena más pequeña de *[Bits](https://es.wikipedia.org/wiki/Bit)*. Es decir, que intentando medir cuan poco predecible es una cadena de *[Bits](https://es.wikipedia.org/wiki/Bit)*,  [Shannon](https://es.wikipedia.org/wiki/Claude_Elwood_Shannon) esperaba poder encontrar *cuánta información* contenía el mensaje. \n",
    "\n",
    "## Redundancia\n",
    "\n",
    "Para explorar en carne propia como la *información* es una medida de sorpresa y como la mayoría de los mensajes contienen bastantes *[Bits](https://es.wikipedia.org/wiki/Bit)* redundantes, les dejo otro juego; la idea es adivinar nombres que empiezan con \"R\" de Raúl a medida que se van descubriendo nuevas letras. Les garantizo que podrán descubrir los nombres sin tener que llegar que se descubra la última letra!\n",
    "<br>\n",
    "<button onclick=\"adivinar_nombres()\">Jugar a Adivinar el nombre!</button>\n",
    "\n",
    "<script>\n",
    "function adivinar_nombres(){\n",
    "  var nombres_R = [\n",
    "    \"ramses\", \"rodolfo\", \"regina\", \"ruth\", \"ramiro\",\n",
    "    \"ramon\", \"roxana\", \"rebeca\", \"raquel\", \"ruben\",\n",
    "    \"rosario\", \"renata\", \"raul\", \"romina\", \"roberto\",\n",
    "    \"ricardo\", \"rafael\", \"rosa\", \"rodrigo\", \"rocio\"\n",
    "  ]\n",
    "  var index = Math.floor(Math.random()*20) - 1;\n",
    "  var mi_nombre = nombres_R[index];\n",
    "  var bits = 1;\n",
    "  var tu_nombre = prompt(\"Adivina el nombre! Empieza con R y tiene \" + mi_nombre.length + \" letras: \").toLowerCase();\n",
    "  var letras = 2;\n",
    "  while (mi_nombre != tu_nombre) {\n",
    "    mi_nombre_parcial = mi_nombre.substring(0, letras);\n",
    "    if (mi_nombre_parcial === mi_nombre) {\n",
    "      break;\n",
    "    }\n",
    "    tu_nombre = prompt(\"Inténtalo otra vez! Empieza con \" + mi_nombre_parcial + \" y tiene \"+ mi_nombre.length + \" letras: \").toLowerCase();\n",
    "    bits++;\n",
    "    letras++;\n",
    "  }\n",
    "  alert(\"El nombre es \" + mi_nombre.toUpperCase() + \"! y has utilizado \" + bits + \" bits! Los restantes \" + (mi_nombre.length - bits) + \" son redundantes!\" );\n",
    "}\n",
    "</script>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Información e incertidumbre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Este post fue escrito utilizando [Jupyter notebook](https://jupyter.org/). Pueden descargar este [notebook](https://github.com/relopezbriega/relopezbriega.github.io/blob/master/downloads/pyInformationTheory.ipynb) o ver su version estática en [nbviewer](https://nbviewer.ipython.org/github/relopezbriega/relopezbriega.github.io/blob/master/downloads/pyInformationTheory.ipynb).*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
